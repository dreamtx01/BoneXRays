{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adejuwon/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__\n",
    "import numpy as np \n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from skimage.io import imread\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import f1_score,confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "# Remove warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scans_df = pd.DataFrame(dict(path = glob(os.path.join('MURA-v1.1', '*', '*', '*', '*', '*.png'))))\n",
    "all_scans_df['TrainSplit'] = all_scans_df['path'].map(lambda x: x.split('/')[-5])\n",
    "all_scans_df['Region'] = all_scans_df['path'].map(lambda x: x.split('/')[2])\n",
    "all_scans_df['Patient'] = all_scans_df['path'].map(lambda x: x.split('/')[-3])\n",
    "all_scans_df['FolderId'] = all_scans_df['path'].map(lambda x: x.split('/')[-2])\n",
    "all_scans_df['Study'] = all_scans_df['FolderId'].map(lambda x: x.split('_')[0])\n",
    "all_scans_df['classes'] = all_scans_df['FolderId'].map(lambda x: x.split('_')[-1] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob(os.path.join('MURA-v1.1', '*', '*', '*', '*', '*.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results for the FOREARM images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.94      0.68        69\n",
      "         1.0       0.64      0.11      0.19        64\n",
      "\n",
      "    accuracy                           0.54       133\n",
      "   macro avg       0.58      0.53      0.43       133\n",
      "weighted avg       0.58      0.54      0.44       133\n",
      "\n",
      "Here are the results for the HAND images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.98      0.75       101\n",
      "         1.0       0.60      0.05      0.08        66\n",
      "\n",
      "    accuracy                           0.61       167\n",
      "   macro avg       0.61      0.51      0.42       167\n",
      "weighted avg       0.61      0.61      0.49       167\n",
      "\n",
      "Here are the results for the WRIST images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.83      0.69       140\n",
      "         1.0       0.43      0.19      0.26        97\n",
      "\n",
      "    accuracy                           0.57       237\n",
      "   macro avg       0.51      0.51      0.48       237\n",
      "weighted avg       0.53      0.57      0.52       237\n",
      "\n",
      "Here are the results for the SHOULDER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.45      0.49        99\n",
      "         1.0       0.50      0.58      0.54        95\n",
      "\n",
      "    accuracy                           0.52       194\n",
      "   macro avg       0.52      0.52      0.51       194\n",
      "weighted avg       0.52      0.52      0.51       194\n",
      "\n",
      "Here are the results for the FINGER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.87      0.74        92\n",
      "         1.0       0.76      0.46      0.57        83\n",
      "\n",
      "    accuracy                           0.67       175\n",
      "   macro avg       0.70      0.66      0.65       175\n",
      "weighted avg       0.70      0.67      0.66       175\n",
      "\n",
      "Here are the results for the HUMERUS images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.58      0.54      0.56        68\n",
      "         1.0       0.56      0.60      0.58        67\n",
      "\n",
      "    accuracy                           0.57       135\n",
      "   macro avg       0.57      0.57      0.57       135\n",
      "weighted avg       0.57      0.57      0.57       135\n",
      "\n",
      "Here are the results for the ELBOW images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.93      0.73        92\n",
      "         1.0       0.57      0.12      0.20        66\n",
      "\n",
      "    accuracy                           0.59       158\n",
      "   macro avg       0.58      0.53      0.46       158\n",
      "weighted avg       0.59      0.59      0.51       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def logistic_classifier(x_train, y_train, x_valid):\n",
    "   \n",
    "    log_reg=LogisticRegression(solver=\"sag\",C=100,random_state=10)\n",
    "    log_reg.fit(x_train,y_train)\n",
    "    pred=log_reg.predict(x_valid)\n",
    "    return pred   \n",
    "\"\"\"\n",
    "classification Logistic Classifier\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(csv_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        train_path: path to csv file containing training dataset\n",
    "        valid_path: path to csv file containing validation dataset\n",
    "    Returns:\n",
    "        x's: np array of inputs\n",
    "        y's: np array of labels\n",
    "    \"\"\"\n",
    "    inputs = np.loadtxt(csv_path, delimiter=',')[:, 1:]\n",
    "    labels = np.loadtxt(csv_path, delimiter=',')[:, 0]\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "bodyparts=['FOREARM','HAND','WRIST','SHOULDER','FINGER','HUMERUS','ELBOW']\n",
    "\n",
    "for bodypart in bodyparts:    \n",
    "    if __name__ == '__main__':\n",
    "        x_train, y_train = load_dataset('train_hist_' + bodypart + '.csv')\n",
    "        x_valid, y_valid = load_dataset('valid_hist_' + bodypart + '.csv')\n",
    "        y_pred = logistic_classifier(x_train, y_train, x_valid)\n",
    "    print(f'Here are the results for the {bodypart} images.')\n",
    "    print(classification_report(y_valid, y_pred))\n",
    "    #plt.matshow(confusion_matrix(y_valid,y_pred))\n",
    "\n",
    "    # Create dataframe of scored model\n",
    "global dataframe\n",
    "dataframe = pd.DataFrame(classification_report(y_valid, y_pred, output_dict=True)).transpose()\n",
    "\n",
    "log_reg = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1754, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.array(x_train)\n",
    "print('X_train shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'logisticregression__C': 100, 'logisticregression__solver': 'sag'}\n",
      "best score:  0.6499429874572406\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline\n",
    "pipeline = make_pipeline(LogisticRegression(random_state=10))\n",
    "\n",
    "# Select hyperparameters\n",
    "hyperparameters = {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'logisticregression__solver': ['lbfgs', 'sag', 'saga', 'newton-cg']}\n",
    "\n",
    "# For loop to select best set of features, hyperparameters\n",
    "best_score = 0\n",
    "best_feature = str()\n",
    "best_param = str()\n",
    "# Loop\n",
    "\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5) # Check hyperparameters\n",
    "clf.fit(x_train, y_train)\n",
    "if clf.best_score_ > best_score: # If better than others, save\n",
    "        best_score = clf.best_score_\n",
    "        best_param = clf.best_params_\n",
    "        \n",
    "print('best parameters: ', best_param)\n",
    "print('best score: ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results for the FOREARM images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.77      0.65        69\n",
      "         1.0       0.59      0.36      0.45        64\n",
      "\n",
      "    accuracy                           0.57       133\n",
      "   macro avg       0.58      0.56      0.55       133\n",
      "weighted avg       0.58      0.57      0.55       133\n",
      "\n",
      "Here are the results for the HAND images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.94      0.75       101\n",
      "         1.0       0.62      0.15      0.24        66\n",
      "\n",
      "    accuracy                           0.63       167\n",
      "   macro avg       0.63      0.55      0.50       167\n",
      "weighted avg       0.63      0.63      0.55       167\n",
      "\n",
      "Here are the results for the WRIST images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      0.77      0.72       140\n",
      "         1.0       0.59      0.48      0.53        97\n",
      "\n",
      "    accuracy                           0.65       237\n",
      "   macro avg       0.64      0.63      0.63       237\n",
      "weighted avg       0.65      0.65      0.65       237\n",
      "\n",
      "Here are the results for the SHOULDER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.55      0.58        99\n",
      "         1.0       0.58      0.65      0.61        95\n",
      "\n",
      "    accuracy                           0.60       194\n",
      "   macro avg       0.60      0.60      0.60       194\n",
      "weighted avg       0.60      0.60      0.60       194\n",
      "\n",
      "Here are the results for the FINGER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.84      0.70        92\n",
      "         1.0       0.68      0.39      0.49        83\n",
      "\n",
      "    accuracy                           0.62       175\n",
      "   macro avg       0.64      0.61      0.60       175\n",
      "weighted avg       0.64      0.62      0.60       175\n",
      "\n",
      "Here are the results for the HUMERUS images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.60      0.63        68\n",
      "         1.0       0.63      0.69      0.66        67\n",
      "\n",
      "    accuracy                           0.64       135\n",
      "   macro avg       0.65      0.64      0.64       135\n",
      "weighted avg       0.65      0.64      0.64       135\n",
      "\n",
      "Here are the results for the ELBOW images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.91      0.75        92\n",
      "         1.0       0.69      0.27      0.39        66\n",
      "\n",
      "    accuracy                           0.65       158\n",
      "   macro avg       0.66      0.59      0.57       158\n",
      "weighted avg       0.66      0.65      0.60       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def knn_classifier(x_train, y_train, x_valid):\n",
    "\n",
    "    neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "    neigh.fit(x_train,y_train)\n",
    "    pred_knn=neigh.predict(x_valid)\n",
    "    return pred_knn  \n",
    "\n",
    "bodyparts=['FOREARM','HAND','WRIST','SHOULDER','FINGER','HUMERUS','ELBOW']\n",
    "\n",
    "for bodypart in bodyparts:    \n",
    "        x_train, y_train = load_dataset('train_hist_' + bodypart + '.csv')\n",
    "        x_valid, y_valid = load_dataset('valid_hist_' + bodypart + '.csv')\n",
    "        y_pred = knn_classifier(x_train, y_train, x_valid)\n",
    "        print(f'Here are the results for the {bodypart} images.')\n",
    "        print(classification_report(y_valid, y_pred))\n",
    "\n",
    "knn = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'kneighborsclassifier__n_neighbors': 9}\n",
      "best score:  0.6676168757126568\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline\n",
    "pipeline = make_pipeline(KNeighborsClassifier())\n",
    "\n",
    "# Select hyperparameters\n",
    "hyperparameters = {'kneighborsclassifier__n_neighbors': np.arange(1,10)}\n",
    "\n",
    "# For loop to select best set of features, hyperparameters\n",
    "best_score = 0\n",
    "best_param = str()\n",
    "# Loop\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5) # Check hyperparameters\n",
    "clf.fit(x_train, y_train)\n",
    "if clf.best_score_ > best_score: # If better than others, save\n",
    "        best_score = clf.best_score_\n",
    "        best_param = clf.best_params_\n",
    "        \n",
    "print('best parameters: ', best_param)\n",
    "print('best score: ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results for the FOREARM images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.59      0.91      0.72        69\n",
      "         1.0       0.77      0.31      0.44        64\n",
      "\n",
      "    accuracy                           0.62       133\n",
      "   macro avg       0.68      0.61      0.58       133\n",
      "weighted avg       0.68      0.62      0.59       133\n",
      "\n",
      "Here are the results for the HAND images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.96      0.77       101\n",
      "         1.0       0.75      0.18      0.29        66\n",
      "\n",
      "    accuracy                           0.65       167\n",
      "   macro avg       0.70      0.57      0.53       167\n",
      "weighted avg       0.68      0.65      0.58       167\n",
      "\n",
      "Here are the results for the WRIST images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.70      0.83      0.76       140\n",
      "         1.0       0.66      0.48      0.56        97\n",
      "\n",
      "    accuracy                           0.69       237\n",
      "   macro avg       0.68      0.66      0.66       237\n",
      "weighted avg       0.68      0.69      0.68       237\n",
      "\n",
      "Here are the results for the SHOULDER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.64      0.64        99\n",
      "         1.0       0.62      0.63      0.63        95\n",
      "\n",
      "    accuracy                           0.63       194\n",
      "   macro avg       0.63      0.63      0.63       194\n",
      "weighted avg       0.63      0.63      0.63       194\n",
      "\n",
      "Here are the results for the FINGER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.87      0.76        92\n",
      "         1.0       0.79      0.53      0.63        83\n",
      "\n",
      "    accuracy                           0.71       175\n",
      "   macro avg       0.73      0.70      0.70       175\n",
      "weighted avg       0.73      0.71      0.70       175\n",
      "\n",
      "Here are the results for the HUMERUS images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.79      0.70        68\n",
      "         1.0       0.71      0.52      0.60        67\n",
      "\n",
      "    accuracy                           0.66       135\n",
      "   macro avg       0.67      0.66      0.65       135\n",
      "weighted avg       0.67      0.66      0.65       135\n",
      "\n",
      "Here are the results for the ELBOW images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.93      0.77        92\n",
      "         1.0       0.79      0.33      0.47        66\n",
      "\n",
      "    accuracy                           0.68       158\n",
      "   macro avg       0.72      0.63      0.62       158\n",
      "weighted avg       0.71      0.68      0.65       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def RandomForest(x_train, y_train, x_valid):\n",
    "    clf = RandomForestClassifier(n_estimators=100,random_state=10,max_depth=None)\n",
    "    clf.fit(x_train,y_train)\n",
    "    pred_clf=clf.predict(x_valid)\n",
    "    return pred_clf \n",
    "\n",
    "bodyparts=['FOREARM','HAND','WRIST','SHOULDER','FINGER','HUMERUS','ELBOW']\n",
    "\n",
    "for bodypart in bodyparts:    \n",
    "        x_train, y_train = load_dataset('train_hist_' + bodypart + '.csv')\n",
    "        x_valid, y_valid = load_dataset('valid_hist_' + bodypart + '.csv')\n",
    "        y_pred = RandomForest(x_train, y_train, x_valid)\n",
    "        print(f'Here are the results for the {bodypart} images.')\n",
    "        print(classification_report(y_valid, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "random_forest = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'randomforestclassifier__max_depth': None, 'randomforestclassifier__n_estimators': 100}\n",
      "best score:  0.7069555302166477\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline\n",
    "pipeline = make_pipeline(RandomForestClassifier(random_state=10))\n",
    "\n",
    "# Select hyperparameters\n",
    "hyperparameters = {\n",
    "                  'randomforestclassifier__max_depth': [None, 5, 3, 1],\n",
    "                  'randomforestclassifier__n_estimators': [10, 25, 50, 75, 100]}\n",
    "\n",
    "# For loop to select best set of features, hyperparameters\n",
    "best_score = 0\n",
    "best_param = str()\n",
    "\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5) # Check hyperparameters\n",
    "clf.fit(x_train, y_train)\n",
    "if clf.best_score_ > best_score: # If better than others, save\n",
    "        best_score = clf.best_score_\n",
    "        best_param = clf.best_params_\n",
    "        \n",
    "print('best parameters: ', best_param)\n",
    "print('best score: ', best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results for the FOREARM images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.56      0.83      0.67        69\n",
      "         1.0       0.62      0.31      0.42        64\n",
      "\n",
      "    accuracy                           0.58       133\n",
      "   macro avg       0.59      0.57      0.54       133\n",
      "weighted avg       0.59      0.58      0.55       133\n",
      "\n",
      "Here are the results for the HAND images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.99      0.76       101\n",
      "         1.0       0.80      0.06      0.11        66\n",
      "\n",
      "    accuracy                           0.62       167\n",
      "   macro avg       0.71      0.53      0.44       167\n",
      "weighted avg       0.69      0.62      0.50       167\n",
      "\n",
      "Here are the results for the WRIST images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.80      0.73       140\n",
      "         1.0       0.60      0.43      0.50        97\n",
      "\n",
      "    accuracy                           0.65       237\n",
      "   macro avg       0.64      0.62      0.62       237\n",
      "weighted avg       0.64      0.65      0.64       237\n",
      "\n",
      "Here are the results for the SHOULDER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.58      0.59        99\n",
      "         1.0       0.58      0.61      0.59        95\n",
      "\n",
      "    accuracy                           0.59       194\n",
      "   macro avg       0.59      0.59      0.59       194\n",
      "weighted avg       0.59      0.59      0.59       194\n",
      "\n",
      "Here are the results for the FINGER images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.65      0.88      0.75        92\n",
      "         1.0       0.78      0.47      0.59        83\n",
      "\n",
      "    accuracy                           0.69       175\n",
      "   macro avg       0.71      0.68      0.67       175\n",
      "weighted avg       0.71      0.69      0.67       175\n",
      "\n",
      "Here are the results for the HUMERUS images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.62      0.64        68\n",
      "         1.0       0.64      0.69      0.66        67\n",
      "\n",
      "    accuracy                           0.65       135\n",
      "   macro avg       0.65      0.65      0.65       135\n",
      "weighted avg       0.65      0.65      0.65       135\n",
      "\n",
      "Here are the results for the ELBOW images.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.93      0.75        92\n",
      "         1.0       0.70      0.21      0.33        66\n",
      "\n",
      "    accuracy                           0.63       158\n",
      "   macro avg       0.66      0.57      0.54       158\n",
      "weighted avg       0.66      0.63      0.57       158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def svm_classifier(x_train, y_train, x_valid):\n",
    "   \n",
    "    clf=svm.SVC(C=100,gamma=1,kernel=\"rbf\")\n",
    "    clf.fit(x_train,y_train)\n",
    "    pred_svm=clf.predict(x_valid)\n",
    "    return pred_svm    \n",
    "\n",
    "\"\"\"\n",
    "classification SVM\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_dataset(csv_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        train_path: path to csv file containing training dataset\n",
    "        valid_path: path to csv file containing validation dataset\n",
    "    Returns:\n",
    "        x's: np array of inputs\n",
    "        y's: np array of labels\n",
    "    \"\"\"\n",
    "    inputs = np.loadtxt(csv_path, delimiter=',')[:, 1:]\n",
    "    labels = np.loadtxt(csv_path, delimiter=',')[:, 0]\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "bodyparts=['FOREARM','HAND','WRIST','SHOULDER','FINGER','HUMERUS','ELBOW']\n",
    "\n",
    "for bodypart in bodyparts:    \n",
    "    if __name__ == '__main__':\n",
    "        x_train, y_train = load_dataset('train_hist_' + bodypart + '.csv')\n",
    "        x_valid, y_valid = load_dataset('valid_hist_' + bodypart + '.csv')\n",
    "        y_pred = svm_classifier(x_train, y_train, x_valid)\n",
    "    print(f'Here are the results for the {bodypart} images.')\n",
    "    print(classification_report(y_valid, y_pred))\n",
    "    #plt.matshow(confusion_matrix(y_valid,y_pred))\n",
    "\n",
    "svm = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters:  {'svc__C': 100, 'svc__gamma': 1, 'svc__kernel': 'rbf'}\n",
      "best score:  0.6721778791334093\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline\n",
    "pipeline = make_pipeline(SVC(random_state=10))\n",
    "\n",
    "# Select hyperparameters\n",
    "hyperparameters = {'svc__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'svc__kernel': ['rbf', 'linear'],\n",
    "                  'svc__gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "# For loop to select best set of features, hyperparameters\n",
    "best_score = 0\n",
    "best_param = str()\n",
    "clf = GridSearchCV(pipeline, hyperparameters, cv=5) # Check hyperparameters\n",
    "clf.fit(x_train, y_train)\n",
    "if clf.best_score_ > best_score: # If better than others, save\n",
    "        best_score = clf.best_score_\n",
    "        best_param = clf.best_params_\n",
    "        \n",
    "print('best parameters: ', best_param)\n",
    "print('best score: ', best_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
